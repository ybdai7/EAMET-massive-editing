{
    "archive": "./baselines/mend/pretrained/wikirecent/models/MEND/Llama-2-7b-hf",
    "alg_name": "MEND",
    "device": 0,
    "model_name": "NousResearch/Llama-2-7b-hf",
    "model_class": "LlamaForCausalLM",
    "tokenizer_class": "LlamaTokenizer", 
    "tokenizer_name": "NousResearch/Llama-2-7b-hf",
    "model_parallel": false,
    "inner_params": [
        "model.layers.29.mlp.gate_proj.weight",
        "model.layers.29.mlp.up_proj.weight", 
        "model.layers.29.mlp.down_proj.weight",
        "model.layers.30.mlp.gate_proj.weight",
        "model.layers.30.mlp.up_proj.weight",
        "model.layers.30.mlp.down_proj.weight",
        "model.layers.31.mlp.gate_proj.weight",
        "model.layers.31.mlp.up_proj.weight",
        "model.layers.31.mlp.down_proj.weight"
    ],
    "alg": "MEND",
    "lr": 1e-6,
    "edit_lr": 1e-4,
    "lr_lr": 1e-4,
    "lr_scale": 1.0,
    "seed": 42,
    "cedit": 0.1,
    "cloc": 1.0,
    "cbase": 1.0,
    "dropout": 0.0,
    "train_base": false,
    "no_grad_layers": null,
    "one_sided": false,
    "n_hidden": 1,
    "hidden_dim": null,
    "init": "id",
    "norm": true,
    "combine": true,
    "x_only": false,
    "delta_only": false,
    "act": "relu",
    "rank": 1920,
    "mlp_class": "IDMLP",
    "shared": true,
    "batch_size": 1,
    "model_save_pt": 5000,
    "silent": false,
    "max_iters": 100000,
    "log_interval": 1000,
    "eval_log_interval": 1000,
    "final_eval": true,
    "val_interval": 1000,
    "early_stop_patience": 20000,
    "early_stop_key": "loss/total_edit_val",
    "eval_only": true,
    "half": false,
    "debug": false,
    "save": false,
    "verbose": true,
    "val_batch_size": 5,
    "accumulate_bs": 10,
    "val_steps": 500,
    "opt": "Adam",
    "grad_clip": 100.0,
    "results_dir": "./results/MEND/results/llama-2-7b-wikirecent"
}